{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00839d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914a7c82-0fc8-431d-b06a-95d16ed48c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6c4cf22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db42d4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x77fcddbf2b10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d41cdac",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23a65fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT = 768\n",
    "BATCH = 8\n",
    "\n",
    "VALID_PROP = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb2de18",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2362ba5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at ai-forever/rugpt3small_based_on_gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"ai-forever/rugpt3small_based_on_gpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "model.score = torch.nn.Linear(768, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a56f7d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50264, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834e2f3d",
   "metadata": {},
   "source": [
    "Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "185d6200",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d862bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.score.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.transformer.ln_f.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.transformer.h[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.transformer.h[-2].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.transformer.h[-3].parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0f6ef70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметры с градиентами:\n",
      "✓ transformer.h.9.ln_1.weight\n",
      "✓ transformer.h.9.ln_1.bias\n",
      "✓ transformer.h.9.attn.c_attn.weight\n",
      "✓ transformer.h.9.attn.c_attn.bias\n",
      "✓ transformer.h.9.attn.c_proj.weight\n",
      "✓ transformer.h.9.attn.c_proj.bias\n",
      "✓ transformer.h.9.ln_2.weight\n",
      "✓ transformer.h.9.ln_2.bias\n",
      "✓ transformer.h.9.mlp.c_fc.weight\n",
      "✓ transformer.h.9.mlp.c_fc.bias\n",
      "✓ transformer.h.9.mlp.c_proj.weight\n",
      "✓ transformer.h.9.mlp.c_proj.bias\n",
      "✓ transformer.h.10.ln_1.weight\n",
      "✓ transformer.h.10.ln_1.bias\n",
      "✓ transformer.h.10.attn.c_attn.weight\n",
      "✓ transformer.h.10.attn.c_attn.bias\n",
      "✓ transformer.h.10.attn.c_proj.weight\n",
      "✓ transformer.h.10.attn.c_proj.bias\n",
      "✓ transformer.h.10.ln_2.weight\n",
      "✓ transformer.h.10.ln_2.bias\n",
      "✓ transformer.h.10.mlp.c_fc.weight\n",
      "✓ transformer.h.10.mlp.c_fc.bias\n",
      "✓ transformer.h.10.mlp.c_proj.weight\n",
      "✓ transformer.h.10.mlp.c_proj.bias\n",
      "✓ transformer.h.11.ln_1.weight\n",
      "✓ transformer.h.11.ln_1.bias\n",
      "✓ transformer.h.11.attn.c_attn.weight\n",
      "✓ transformer.h.11.attn.c_attn.bias\n",
      "✓ transformer.h.11.attn.c_proj.weight\n",
      "✓ transformer.h.11.attn.c_proj.bias\n",
      "✓ transformer.h.11.ln_2.weight\n",
      "✓ transformer.h.11.ln_2.bias\n",
      "✓ transformer.h.11.mlp.c_fc.weight\n",
      "✓ transformer.h.11.mlp.c_fc.bias\n",
      "✓ transformer.h.11.mlp.c_proj.weight\n",
      "✓ transformer.h.11.mlp.c_proj.bias\n",
      "✓ transformer.ln_f.weight\n",
      "✓ transformer.ln_f.bias\n",
      "✓ score.weight\n",
      "✓ score.bias\n",
      "\n",
      "Обучаемые параметры: 21267459/125233923 (17.0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Параметры с градиентами:\")\n",
    "total_params = 0\n",
    "trainable_params = 0\n",
    "for name, param in model.named_parameters():\n",
    "    total_params += param.numel()\n",
    "    if param.requires_grad:\n",
    "        trainable_params += param.numel()\n",
    "        print(f\"✓ {name}\")\n",
    "\n",
    "print(f\"\\nОбучаемые параметры: {trainable_params}/{total_params} ({trainable_params/total_params*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c631c903",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6ee91d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from analysis.precomposed.TorchDataset import TorchDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a516a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./analysis/data/dataset_onehot.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1db8cfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = data.sample(n=int(data.shape[0]*VALID_PROP))\n",
    "data_train = data.drop(index=data_val.index)\n",
    "\n",
    "data_train.reset_index(inplace=True, drop=True)\n",
    "data_val.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00e512cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's go!\n",
      "Let's go!\n"
     ]
    }
   ],
   "source": [
    "ds_train = TorchDataset(data= data_train, tokenizer = tokenizer, context_l = CONTEXT)\n",
    "ds_valid = TorchDataset(data= data_val, tokenizer = tokenizer, context_l = CONTEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d77c757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size= BATCH, shuffle= True)\n",
    "dl_valid = DataLoader(ds_valid, batch_size= BATCH, shuffle= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0d25f1",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7337e2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eda5b67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29d7e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "TOTAL_BATCHES = len(dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e218688",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = opt.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "scheduler = opt.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "best_val_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fe39a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                                                                                               | 0/20 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2192 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Epoch:  10%|████▋                                          | 2/20 [1:23:49<12:34:35, 2515.30s/it, train_loss=0.2371, val_loss=0.2024, lr=1.00e-04]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|███████████▊                                   | 5/20 [3:28:37<10:25:37, 2502.51s/it, train_loss=0.1655, val_loss=0.2023, lr=1.00e-05]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  65%|██████████████████████████████▌                | 13/20 [9:40:02<5:12:19, 2677.11s/it, train_loss=0.0705, val_loss=0.2767, lr=1.00e-06]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m             v_loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m---> 27\u001b[0m         valid_losses\u001b[38;5;241m.\u001b[39mappend(\u001b[43mv_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     29\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(train_losses) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_losses)\n\u001b[1;32m     30\u001b[0m avg_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(valid_losses) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(valid_losses)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pbar = tqdm(range(EPOCHS), desc=\"Epoch\")\n",
    "for epoch in pbar:\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for batch_idx, (data, targets) in enumerate(dl_train):\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        if hasattr(outputs, 'logits'):\n",
    "            loss = criterion(outputs.logits, targets)\n",
    "        else:\n",
    "            loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    valid_losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, targets) in enumerate(dl_valid):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            if hasattr(outputs, 'logits'):\n",
    "                v_loss = criterion(outputs.logits, targets)\n",
    "            else:\n",
    "                v_loss = criterion(outputs, targets)\n",
    "            valid_losses.append(v_loss.item())\n",
    "\n",
    "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "    avg_val_loss = sum(valid_losses) / len(valid_losses)\n",
    "    scheduler.step()\n",
    "    pbar.set_postfix({\n",
    "        'train_loss': f'{avg_train_loss:.4f}',\n",
    "        'val_loss': f'{avg_val_loss:.4f}',\n",
    "        'lr': f'{scheduler.get_last_lr()[0]:.2e}'\n",
    "    })\n",
    "\n",
    "    if (avg_val_loss < best_val_loss and avg_val_loss < 0.25):\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model, f'./analysis/neural_training/rugpt3s_{int(best_val_loss*10**6)}.pth')\n",
    "        print(\"Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cebbc7",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "575ca92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = torch.load(\"./analysis/neural_training/rugpt3s_202349.pth\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1e82c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def calculate_class_accuracy(model, dataloader, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    _batch = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            _batch+=1\n",
    "            print(f\"[PREDICTIONS] BATCH: {_batch}/{len(dataloader)}\")\n",
    "            if isinstance(batch, (list, tuple)):\n",
    "                inputs = batch[0]\n",
    "                targets = batch[1]\n",
    "            else:\n",
    "                inputs = batch\n",
    "                targets = batch['labels']\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            if isinstance(outputs, (tuple, list)):\n",
    "                logits = outputs[0]\n",
    "            else:\n",
    "                logits = outputs\n",
    "            \n",
    "            predictions = torch.argmax(logits.logits, dim=1)\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_targets.extend(torch.argmax(targets, dim=1).cpu().numpy())\n",
    "    \n",
    "    predictions = np.array(all_predictions)\n",
    "    targets = np.array(all_targets)\n",
    "    \n",
    "    class_accuracies = {}\n",
    "    \n",
    "    for class_idx, class_name in enumerate(['SPAM', 'TOXIC', 'OK']):\n",
    "        class_mask = targets == class_idx\n",
    "        if np.sum(class_mask) > 0:\n",
    "            class_accuracy = accuracy_score(\n",
    "                targets[class_mask], \n",
    "                predictions[class_mask]\n",
    "            )\n",
    "            class_accuracies[class_name] = class_accuracy\n",
    "        else:\n",
    "            class_accuracies[class_name] = 0.0\n",
    "    \n",
    "    total_accuracy = accuracy_score(targets, predictions)\n",
    "    class_accuracies['TOTAL'] = total_accuracy\n",
    "    \n",
    "    return class_accuracies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bf0d9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PREDICTIONS] BATCH: 1/710\n",
      "[PREDICTIONS] BATCH: 2/710\n",
      "[PREDICTIONS] BATCH: 3/710\n",
      "[PREDICTIONS] BATCH: 4/710\n",
      "[PREDICTIONS] BATCH: 5/710\n",
      "[PREDICTIONS] BATCH: 6/710\n",
      "[PREDICTIONS] BATCH: 7/710\n",
      "[PREDICTIONS] BATCH: 8/710\n",
      "[PREDICTIONS] BATCH: 9/710\n",
      "[PREDICTIONS] BATCH: 10/710\n",
      "[PREDICTIONS] BATCH: 11/710\n",
      "[PREDICTIONS] BATCH: 12/710\n",
      "[PREDICTIONS] BATCH: 13/710\n",
      "[PREDICTIONS] BATCH: 14/710\n",
      "[PREDICTIONS] BATCH: 15/710\n",
      "[PREDICTIONS] BATCH: 16/710\n",
      "[PREDICTIONS] BATCH: 17/710\n",
      "[PREDICTIONS] BATCH: 18/710\n",
      "[PREDICTIONS] BATCH: 19/710\n",
      "[PREDICTIONS] BATCH: 20/710\n",
      "[PREDICTIONS] BATCH: 21/710\n",
      "[PREDICTIONS] BATCH: 22/710\n",
      "[PREDICTIONS] BATCH: 23/710\n",
      "[PREDICTIONS] BATCH: 24/710\n",
      "[PREDICTIONS] BATCH: 25/710\n",
      "[PREDICTIONS] BATCH: 26/710\n",
      "[PREDICTIONS] BATCH: 27/710\n",
      "[PREDICTIONS] BATCH: 28/710\n",
      "[PREDICTIONS] BATCH: 29/710\n",
      "[PREDICTIONS] BATCH: 30/710\n",
      "[PREDICTIONS] BATCH: 31/710\n",
      "[PREDICTIONS] BATCH: 32/710\n",
      "[PREDICTIONS] BATCH: 33/710\n",
      "[PREDICTIONS] BATCH: 34/710\n",
      "[PREDICTIONS] BATCH: 35/710\n",
      "[PREDICTIONS] BATCH: 36/710\n",
      "[PREDICTIONS] BATCH: 37/710\n",
      "[PREDICTIONS] BATCH: 38/710\n",
      "[PREDICTIONS] BATCH: 39/710\n",
      "[PREDICTIONS] BATCH: 40/710\n",
      "[PREDICTIONS] BATCH: 41/710\n",
      "[PREDICTIONS] BATCH: 42/710\n",
      "[PREDICTIONS] BATCH: 43/710\n",
      "[PREDICTIONS] BATCH: 44/710\n",
      "[PREDICTIONS] BATCH: 45/710\n",
      "[PREDICTIONS] BATCH: 46/710\n",
      "[PREDICTIONS] BATCH: 47/710\n",
      "[PREDICTIONS] BATCH: 48/710\n",
      "[PREDICTIONS] BATCH: 49/710\n",
      "[PREDICTIONS] BATCH: 50/710\n",
      "[PREDICTIONS] BATCH: 51/710\n",
      "[PREDICTIONS] BATCH: 52/710\n",
      "[PREDICTIONS] BATCH: 53/710\n",
      "[PREDICTIONS] BATCH: 54/710\n",
      "[PREDICTIONS] BATCH: 55/710\n",
      "[PREDICTIONS] BATCH: 56/710\n",
      "[PREDICTIONS] BATCH: 57/710\n",
      "[PREDICTIONS] BATCH: 58/710\n",
      "[PREDICTIONS] BATCH: 59/710\n",
      "[PREDICTIONS] BATCH: 60/710\n",
      "[PREDICTIONS] BATCH: 61/710\n",
      "[PREDICTIONS] BATCH: 62/710\n",
      "[PREDICTIONS] BATCH: 63/710\n",
      "[PREDICTIONS] BATCH: 64/710\n",
      "[PREDICTIONS] BATCH: 65/710\n",
      "[PREDICTIONS] BATCH: 66/710\n",
      "[PREDICTIONS] BATCH: 67/710\n",
      "[PREDICTIONS] BATCH: 68/710\n",
      "[PREDICTIONS] BATCH: 69/710\n",
      "[PREDICTIONS] BATCH: 70/710\n",
      "[PREDICTIONS] BATCH: 71/710\n",
      "[PREDICTIONS] BATCH: 72/710\n",
      "[PREDICTIONS] BATCH: 73/710\n",
      "[PREDICTIONS] BATCH: 74/710\n",
      "[PREDICTIONS] BATCH: 75/710\n",
      "[PREDICTIONS] BATCH: 76/710\n",
      "[PREDICTIONS] BATCH: 77/710\n",
      "[PREDICTIONS] BATCH: 78/710\n",
      "[PREDICTIONS] BATCH: 79/710\n",
      "[PREDICTIONS] BATCH: 80/710\n",
      "[PREDICTIONS] BATCH: 81/710\n",
      "[PREDICTIONS] BATCH: 82/710\n",
      "[PREDICTIONS] BATCH: 83/710\n",
      "[PREDICTIONS] BATCH: 84/710\n",
      "[PREDICTIONS] BATCH: 85/710\n",
      "[PREDICTIONS] BATCH: 86/710\n",
      "[PREDICTIONS] BATCH: 87/710\n",
      "[PREDICTIONS] BATCH: 88/710\n",
      "[PREDICTIONS] BATCH: 89/710\n",
      "[PREDICTIONS] BATCH: 90/710\n",
      "[PREDICTIONS] BATCH: 91/710\n",
      "[PREDICTIONS] BATCH: 92/710\n",
      "[PREDICTIONS] BATCH: 93/710\n",
      "[PREDICTIONS] BATCH: 94/710\n",
      "[PREDICTIONS] BATCH: 95/710\n",
      "[PREDICTIONS] BATCH: 96/710\n",
      "[PREDICTIONS] BATCH: 97/710\n",
      "[PREDICTIONS] BATCH: 98/710\n",
      "[PREDICTIONS] BATCH: 99/710\n",
      "[PREDICTIONS] BATCH: 100/710\n",
      "[PREDICTIONS] BATCH: 101/710\n",
      "[PREDICTIONS] BATCH: 102/710\n",
      "[PREDICTIONS] BATCH: 103/710\n",
      "[PREDICTIONS] BATCH: 104/710\n",
      "[PREDICTIONS] BATCH: 105/710\n",
      "[PREDICTIONS] BATCH: 106/710\n",
      "[PREDICTIONS] BATCH: 107/710\n",
      "[PREDICTIONS] BATCH: 108/710\n",
      "[PREDICTIONS] BATCH: 109/710\n",
      "[PREDICTIONS] BATCH: 110/710\n",
      "[PREDICTIONS] BATCH: 111/710\n",
      "[PREDICTIONS] BATCH: 112/710\n",
      "[PREDICTIONS] BATCH: 113/710\n",
      "[PREDICTIONS] BATCH: 114/710\n",
      "[PREDICTIONS] BATCH: 115/710\n",
      "[PREDICTIONS] BATCH: 116/710\n",
      "[PREDICTIONS] BATCH: 117/710\n",
      "[PREDICTIONS] BATCH: 118/710\n",
      "[PREDICTIONS] BATCH: 119/710\n",
      "[PREDICTIONS] BATCH: 120/710\n",
      "[PREDICTIONS] BATCH: 121/710\n",
      "[PREDICTIONS] BATCH: 122/710\n",
      "[PREDICTIONS] BATCH: 123/710\n",
      "[PREDICTIONS] BATCH: 124/710\n",
      "[PREDICTIONS] BATCH: 125/710\n",
      "[PREDICTIONS] BATCH: 126/710\n",
      "[PREDICTIONS] BATCH: 127/710\n",
      "[PREDICTIONS] BATCH: 128/710\n",
      "[PREDICTIONS] BATCH: 129/710\n",
      "[PREDICTIONS] BATCH: 130/710\n",
      "[PREDICTIONS] BATCH: 131/710\n",
      "[PREDICTIONS] BATCH: 132/710\n",
      "[PREDICTIONS] BATCH: 133/710\n",
      "[PREDICTIONS] BATCH: 134/710\n",
      "[PREDICTIONS] BATCH: 135/710\n",
      "[PREDICTIONS] BATCH: 136/710\n",
      "[PREDICTIONS] BATCH: 137/710\n",
      "[PREDICTIONS] BATCH: 138/710\n",
      "[PREDICTIONS] BATCH: 139/710\n",
      "[PREDICTIONS] BATCH: 140/710\n",
      "[PREDICTIONS] BATCH: 141/710\n",
      "[PREDICTIONS] BATCH: 142/710\n",
      "[PREDICTIONS] BATCH: 143/710\n",
      "[PREDICTIONS] BATCH: 144/710\n",
      "[PREDICTIONS] BATCH: 145/710\n",
      "[PREDICTIONS] BATCH: 146/710\n",
      "[PREDICTIONS] BATCH: 147/710\n",
      "[PREDICTIONS] BATCH: 148/710\n",
      "[PREDICTIONS] BATCH: 149/710\n",
      "[PREDICTIONS] BATCH: 150/710\n",
      "[PREDICTIONS] BATCH: 151/710\n",
      "[PREDICTIONS] BATCH: 152/710\n",
      "[PREDICTIONS] BATCH: 153/710\n",
      "[PREDICTIONS] BATCH: 154/710\n",
      "[PREDICTIONS] BATCH: 155/710\n",
      "[PREDICTIONS] BATCH: 156/710\n",
      "[PREDICTIONS] BATCH: 157/710\n",
      "[PREDICTIONS] BATCH: 158/710\n",
      "[PREDICTIONS] BATCH: 159/710\n",
      "[PREDICTIONS] BATCH: 160/710\n",
      "[PREDICTIONS] BATCH: 161/710\n",
      "[PREDICTIONS] BATCH: 162/710\n",
      "[PREDICTIONS] BATCH: 163/710\n",
      "[PREDICTIONS] BATCH: 164/710\n",
      "[PREDICTIONS] BATCH: 165/710\n",
      "[PREDICTIONS] BATCH: 166/710\n",
      "[PREDICTIONS] BATCH: 167/710\n",
      "[PREDICTIONS] BATCH: 168/710\n",
      "[PREDICTIONS] BATCH: 169/710\n",
      "[PREDICTIONS] BATCH: 170/710\n",
      "[PREDICTIONS] BATCH: 171/710\n",
      "[PREDICTIONS] BATCH: 172/710\n",
      "[PREDICTIONS] BATCH: 173/710\n",
      "[PREDICTIONS] BATCH: 174/710\n",
      "[PREDICTIONS] BATCH: 175/710\n",
      "[PREDICTIONS] BATCH: 176/710\n",
      "[PREDICTIONS] BATCH: 177/710\n",
      "[PREDICTIONS] BATCH: 178/710\n",
      "[PREDICTIONS] BATCH: 179/710\n",
      "[PREDICTIONS] BATCH: 180/710\n",
      "[PREDICTIONS] BATCH: 181/710\n",
      "[PREDICTIONS] BATCH: 182/710\n",
      "[PREDICTIONS] BATCH: 183/710\n",
      "[PREDICTIONS] BATCH: 184/710\n",
      "[PREDICTIONS] BATCH: 185/710\n",
      "[PREDICTIONS] BATCH: 186/710\n",
      "[PREDICTIONS] BATCH: 187/710\n",
      "[PREDICTIONS] BATCH: 188/710\n",
      "[PREDICTIONS] BATCH: 189/710\n",
      "[PREDICTIONS] BATCH: 190/710\n",
      "[PREDICTIONS] BATCH: 191/710\n",
      "[PREDICTIONS] BATCH: 192/710\n",
      "[PREDICTIONS] BATCH: 193/710\n",
      "[PREDICTIONS] BATCH: 194/710\n",
      "[PREDICTIONS] BATCH: 195/710\n",
      "[PREDICTIONS] BATCH: 196/710\n",
      "[PREDICTIONS] BATCH: 197/710\n",
      "[PREDICTIONS] BATCH: 198/710\n",
      "[PREDICTIONS] BATCH: 199/710\n",
      "[PREDICTIONS] BATCH: 200/710\n",
      "[PREDICTIONS] BATCH: 201/710\n",
      "[PREDICTIONS] BATCH: 202/710\n",
      "[PREDICTIONS] BATCH: 203/710\n",
      "[PREDICTIONS] BATCH: 204/710\n",
      "[PREDICTIONS] BATCH: 205/710\n",
      "[PREDICTIONS] BATCH: 206/710\n",
      "[PREDICTIONS] BATCH: 207/710\n",
      "[PREDICTIONS] BATCH: 208/710\n",
      "[PREDICTIONS] BATCH: 209/710\n",
      "[PREDICTIONS] BATCH: 210/710\n",
      "[PREDICTIONS] BATCH: 211/710\n",
      "[PREDICTIONS] BATCH: 212/710\n",
      "[PREDICTIONS] BATCH: 213/710\n",
      "[PREDICTIONS] BATCH: 214/710\n",
      "[PREDICTIONS] BATCH: 215/710\n",
      "[PREDICTIONS] BATCH: 216/710\n",
      "[PREDICTIONS] BATCH: 217/710\n",
      "[PREDICTIONS] BATCH: 218/710\n",
      "[PREDICTIONS] BATCH: 219/710\n",
      "[PREDICTIONS] BATCH: 220/710\n",
      "[PREDICTIONS] BATCH: 221/710\n",
      "[PREDICTIONS] BATCH: 222/710\n",
      "[PREDICTIONS] BATCH: 223/710\n",
      "[PREDICTIONS] BATCH: 224/710\n",
      "[PREDICTIONS] BATCH: 225/710\n",
      "[PREDICTIONS] BATCH: 226/710\n",
      "[PREDICTIONS] BATCH: 227/710\n",
      "[PREDICTIONS] BATCH: 228/710\n",
      "[PREDICTIONS] BATCH: 229/710\n",
      "[PREDICTIONS] BATCH: 230/710\n",
      "[PREDICTIONS] BATCH: 231/710\n",
      "[PREDICTIONS] BATCH: 232/710\n",
      "[PREDICTIONS] BATCH: 233/710\n",
      "[PREDICTIONS] BATCH: 234/710\n",
      "[PREDICTIONS] BATCH: 235/710\n",
      "[PREDICTIONS] BATCH: 236/710\n",
      "[PREDICTIONS] BATCH: 237/710\n",
      "[PREDICTIONS] BATCH: 238/710\n",
      "[PREDICTIONS] BATCH: 239/710\n",
      "[PREDICTIONS] BATCH: 240/710\n",
      "[PREDICTIONS] BATCH: 241/710\n",
      "[PREDICTIONS] BATCH: 242/710\n",
      "[PREDICTIONS] BATCH: 243/710\n",
      "[PREDICTIONS] BATCH: 244/710\n",
      "[PREDICTIONS] BATCH: 245/710\n",
      "[PREDICTIONS] BATCH: 246/710\n",
      "[PREDICTIONS] BATCH: 247/710\n",
      "[PREDICTIONS] BATCH: 248/710\n",
      "[PREDICTIONS] BATCH: 249/710\n",
      "[PREDICTIONS] BATCH: 250/710\n",
      "[PREDICTIONS] BATCH: 251/710\n",
      "[PREDICTIONS] BATCH: 252/710\n",
      "[PREDICTIONS] BATCH: 253/710\n",
      "[PREDICTIONS] BATCH: 254/710\n",
      "[PREDICTIONS] BATCH: 255/710\n",
      "[PREDICTIONS] BATCH: 256/710\n",
      "[PREDICTIONS] BATCH: 257/710\n",
      "[PREDICTIONS] BATCH: 258/710\n",
      "[PREDICTIONS] BATCH: 259/710\n",
      "[PREDICTIONS] BATCH: 260/710\n",
      "[PREDICTIONS] BATCH: 261/710\n",
      "[PREDICTIONS] BATCH: 262/710\n",
      "[PREDICTIONS] BATCH: 263/710\n",
      "[PREDICTIONS] BATCH: 264/710\n",
      "[PREDICTIONS] BATCH: 265/710\n",
      "[PREDICTIONS] BATCH: 266/710\n",
      "[PREDICTIONS] BATCH: 267/710\n",
      "[PREDICTIONS] BATCH: 268/710\n",
      "[PREDICTIONS] BATCH: 269/710\n",
      "[PREDICTIONS] BATCH: 270/710\n",
      "[PREDICTIONS] BATCH: 271/710\n",
      "[PREDICTIONS] BATCH: 272/710\n",
      "[PREDICTIONS] BATCH: 273/710\n",
      "[PREDICTIONS] BATCH: 274/710\n",
      "[PREDICTIONS] BATCH: 275/710\n",
      "[PREDICTIONS] BATCH: 276/710\n",
      "[PREDICTIONS] BATCH: 277/710\n",
      "[PREDICTIONS] BATCH: 278/710\n",
      "[PREDICTIONS] BATCH: 279/710\n",
      "[PREDICTIONS] BATCH: 280/710\n",
      "[PREDICTIONS] BATCH: 281/710\n",
      "[PREDICTIONS] BATCH: 282/710\n",
      "[PREDICTIONS] BATCH: 283/710\n",
      "[PREDICTIONS] BATCH: 284/710\n",
      "[PREDICTIONS] BATCH: 285/710\n",
      "[PREDICTIONS] BATCH: 286/710\n",
      "[PREDICTIONS] BATCH: 287/710\n",
      "[PREDICTIONS] BATCH: 288/710\n",
      "[PREDICTIONS] BATCH: 289/710\n",
      "[PREDICTIONS] BATCH: 290/710\n",
      "[PREDICTIONS] BATCH: 291/710\n",
      "[PREDICTIONS] BATCH: 292/710\n",
      "[PREDICTIONS] BATCH: 293/710\n",
      "[PREDICTIONS] BATCH: 294/710\n",
      "[PREDICTIONS] BATCH: 295/710\n",
      "[PREDICTIONS] BATCH: 296/710\n",
      "[PREDICTIONS] BATCH: 297/710\n",
      "[PREDICTIONS] BATCH: 298/710\n",
      "[PREDICTIONS] BATCH: 299/710\n",
      "[PREDICTIONS] BATCH: 300/710\n",
      "[PREDICTIONS] BATCH: 301/710\n",
      "[PREDICTIONS] BATCH: 302/710\n",
      "[PREDICTIONS] BATCH: 303/710\n",
      "[PREDICTIONS] BATCH: 304/710\n",
      "[PREDICTIONS] BATCH: 305/710\n",
      "[PREDICTIONS] BATCH: 306/710\n",
      "[PREDICTIONS] BATCH: 307/710\n",
      "[PREDICTIONS] BATCH: 308/710\n",
      "[PREDICTIONS] BATCH: 309/710\n",
      "[PREDICTIONS] BATCH: 310/710\n",
      "[PREDICTIONS] BATCH: 311/710\n",
      "[PREDICTIONS] BATCH: 312/710\n",
      "[PREDICTIONS] BATCH: 313/710\n",
      "[PREDICTIONS] BATCH: 314/710\n",
      "[PREDICTIONS] BATCH: 315/710\n",
      "[PREDICTIONS] BATCH: 316/710\n",
      "[PREDICTIONS] BATCH: 317/710\n",
      "[PREDICTIONS] BATCH: 318/710\n",
      "[PREDICTIONS] BATCH: 319/710\n",
      "[PREDICTIONS] BATCH: 320/710\n",
      "[PREDICTIONS] BATCH: 321/710\n",
      "[PREDICTIONS] BATCH: 322/710\n",
      "[PREDICTIONS] BATCH: 323/710\n",
      "[PREDICTIONS] BATCH: 324/710\n",
      "[PREDICTIONS] BATCH: 325/710\n",
      "[PREDICTIONS] BATCH: 326/710\n",
      "[PREDICTIONS] BATCH: 327/710\n",
      "[PREDICTIONS] BATCH: 328/710\n",
      "[PREDICTIONS] BATCH: 329/710\n",
      "[PREDICTIONS] BATCH: 330/710\n",
      "[PREDICTIONS] BATCH: 331/710\n",
      "[PREDICTIONS] BATCH: 332/710\n",
      "[PREDICTIONS] BATCH: 333/710\n",
      "[PREDICTIONS] BATCH: 334/710\n",
      "[PREDICTIONS] BATCH: 335/710\n",
      "[PREDICTIONS] BATCH: 336/710\n",
      "[PREDICTIONS] BATCH: 337/710\n",
      "[PREDICTIONS] BATCH: 338/710\n",
      "[PREDICTIONS] BATCH: 339/710\n",
      "[PREDICTIONS] BATCH: 340/710\n",
      "[PREDICTIONS] BATCH: 341/710\n",
      "[PREDICTIONS] BATCH: 342/710\n",
      "[PREDICTIONS] BATCH: 343/710\n",
      "[PREDICTIONS] BATCH: 344/710\n",
      "[PREDICTIONS] BATCH: 345/710\n",
      "[PREDICTIONS] BATCH: 346/710\n",
      "[PREDICTIONS] BATCH: 347/710\n",
      "[PREDICTIONS] BATCH: 348/710\n",
      "[PREDICTIONS] BATCH: 349/710\n",
      "[PREDICTIONS] BATCH: 350/710\n",
      "[PREDICTIONS] BATCH: 351/710\n",
      "[PREDICTIONS] BATCH: 352/710\n",
      "[PREDICTIONS] BATCH: 353/710\n",
      "[PREDICTIONS] BATCH: 354/710\n",
      "[PREDICTIONS] BATCH: 355/710\n",
      "[PREDICTIONS] BATCH: 356/710\n",
      "[PREDICTIONS] BATCH: 357/710\n",
      "[PREDICTIONS] BATCH: 358/710\n",
      "[PREDICTIONS] BATCH: 359/710\n",
      "[PREDICTIONS] BATCH: 360/710\n",
      "[PREDICTIONS] BATCH: 361/710\n",
      "[PREDICTIONS] BATCH: 362/710\n",
      "[PREDICTIONS] BATCH: 363/710\n",
      "[PREDICTIONS] BATCH: 364/710\n",
      "[PREDICTIONS] BATCH: 365/710\n",
      "[PREDICTIONS] BATCH: 366/710\n",
      "[PREDICTIONS] BATCH: 367/710\n",
      "[PREDICTIONS] BATCH: 368/710\n",
      "[PREDICTIONS] BATCH: 369/710\n",
      "[PREDICTIONS] BATCH: 370/710\n",
      "[PREDICTIONS] BATCH: 371/710\n",
      "[PREDICTIONS] BATCH: 372/710\n",
      "[PREDICTIONS] BATCH: 373/710\n",
      "[PREDICTIONS] BATCH: 374/710\n",
      "[PREDICTIONS] BATCH: 375/710\n",
      "[PREDICTIONS] BATCH: 376/710\n",
      "[PREDICTIONS] BATCH: 377/710\n",
      "[PREDICTIONS] BATCH: 378/710\n",
      "[PREDICTIONS] BATCH: 379/710\n",
      "[PREDICTIONS] BATCH: 380/710\n",
      "[PREDICTIONS] BATCH: 381/710\n",
      "[PREDICTIONS] BATCH: 382/710\n",
      "[PREDICTIONS] BATCH: 383/710\n",
      "[PREDICTIONS] BATCH: 384/710\n",
      "[PREDICTIONS] BATCH: 385/710\n",
      "[PREDICTIONS] BATCH: 386/710\n",
      "[PREDICTIONS] BATCH: 387/710\n",
      "[PREDICTIONS] BATCH: 388/710\n",
      "[PREDICTIONS] BATCH: 389/710\n",
      "[PREDICTIONS] BATCH: 390/710\n",
      "[PREDICTIONS] BATCH: 391/710\n",
      "[PREDICTIONS] BATCH: 392/710\n",
      "[PREDICTIONS] BATCH: 393/710\n",
      "[PREDICTIONS] BATCH: 394/710\n",
      "[PREDICTIONS] BATCH: 395/710\n",
      "[PREDICTIONS] BATCH: 396/710\n",
      "[PREDICTIONS] BATCH: 397/710\n",
      "[PREDICTIONS] BATCH: 398/710\n",
      "[PREDICTIONS] BATCH: 399/710\n",
      "[PREDICTIONS] BATCH: 400/710\n",
      "[PREDICTIONS] BATCH: 401/710\n",
      "[PREDICTIONS] BATCH: 402/710\n",
      "[PREDICTIONS] BATCH: 403/710\n",
      "[PREDICTIONS] BATCH: 404/710\n",
      "[PREDICTIONS] BATCH: 405/710\n",
      "[PREDICTIONS] BATCH: 406/710\n",
      "[PREDICTIONS] BATCH: 407/710\n",
      "[PREDICTIONS] BATCH: 408/710\n",
      "[PREDICTIONS] BATCH: 409/710\n",
      "[PREDICTIONS] BATCH: 410/710\n",
      "[PREDICTIONS] BATCH: 411/710\n",
      "[PREDICTIONS] BATCH: 412/710\n",
      "[PREDICTIONS] BATCH: 413/710\n",
      "[PREDICTIONS] BATCH: 414/710\n",
      "[PREDICTIONS] BATCH: 415/710\n",
      "[PREDICTIONS] BATCH: 416/710\n",
      "[PREDICTIONS] BATCH: 417/710\n",
      "[PREDICTIONS] BATCH: 418/710\n",
      "[PREDICTIONS] BATCH: 419/710\n",
      "[PREDICTIONS] BATCH: 420/710\n",
      "[PREDICTIONS] BATCH: 421/710\n",
      "[PREDICTIONS] BATCH: 422/710\n",
      "[PREDICTIONS] BATCH: 423/710\n",
      "[PREDICTIONS] BATCH: 424/710\n",
      "[PREDICTIONS] BATCH: 425/710\n",
      "[PREDICTIONS] BATCH: 426/710\n",
      "[PREDICTIONS] BATCH: 427/710\n",
      "[PREDICTIONS] BATCH: 428/710\n",
      "[PREDICTIONS] BATCH: 429/710\n",
      "[PREDICTIONS] BATCH: 430/710\n",
      "[PREDICTIONS] BATCH: 431/710\n",
      "[PREDICTIONS] BATCH: 432/710\n",
      "[PREDICTIONS] BATCH: 433/710\n",
      "[PREDICTIONS] BATCH: 434/710\n",
      "[PREDICTIONS] BATCH: 435/710\n",
      "[PREDICTIONS] BATCH: 436/710\n",
      "[PREDICTIONS] BATCH: 437/710\n",
      "[PREDICTIONS] BATCH: 438/710\n",
      "[PREDICTIONS] BATCH: 439/710\n",
      "[PREDICTIONS] BATCH: 440/710\n",
      "[PREDICTIONS] BATCH: 441/710\n",
      "[PREDICTIONS] BATCH: 442/710\n",
      "[PREDICTIONS] BATCH: 443/710\n",
      "[PREDICTIONS] BATCH: 444/710\n",
      "[PREDICTIONS] BATCH: 445/710\n",
      "[PREDICTIONS] BATCH: 446/710\n",
      "[PREDICTIONS] BATCH: 447/710\n",
      "[PREDICTIONS] BATCH: 448/710\n",
      "[PREDICTIONS] BATCH: 449/710\n",
      "[PREDICTIONS] BATCH: 450/710\n",
      "[PREDICTIONS] BATCH: 451/710\n",
      "[PREDICTIONS] BATCH: 452/710\n",
      "[PREDICTIONS] BATCH: 453/710\n",
      "[PREDICTIONS] BATCH: 454/710\n",
      "[PREDICTIONS] BATCH: 455/710\n",
      "[PREDICTIONS] BATCH: 456/710\n",
      "[PREDICTIONS] BATCH: 457/710\n",
      "[PREDICTIONS] BATCH: 458/710\n",
      "[PREDICTIONS] BATCH: 459/710\n",
      "[PREDICTIONS] BATCH: 460/710\n",
      "[PREDICTIONS] BATCH: 461/710\n",
      "[PREDICTIONS] BATCH: 462/710\n",
      "[PREDICTIONS] BATCH: 463/710\n",
      "[PREDICTIONS] BATCH: 464/710\n",
      "[PREDICTIONS] BATCH: 465/710\n",
      "[PREDICTIONS] BATCH: 466/710\n",
      "[PREDICTIONS] BATCH: 467/710\n",
      "[PREDICTIONS] BATCH: 468/710\n",
      "[PREDICTIONS] BATCH: 469/710\n",
      "[PREDICTIONS] BATCH: 470/710\n",
      "[PREDICTIONS] BATCH: 471/710\n",
      "[PREDICTIONS] BATCH: 472/710\n",
      "[PREDICTIONS] BATCH: 473/710\n",
      "[PREDICTIONS] BATCH: 474/710\n",
      "[PREDICTIONS] BATCH: 475/710\n",
      "[PREDICTIONS] BATCH: 476/710\n",
      "[PREDICTIONS] BATCH: 477/710\n",
      "[PREDICTIONS] BATCH: 478/710\n",
      "[PREDICTIONS] BATCH: 479/710\n",
      "[PREDICTIONS] BATCH: 480/710\n",
      "[PREDICTIONS] BATCH: 481/710\n",
      "[PREDICTIONS] BATCH: 482/710\n",
      "[PREDICTIONS] BATCH: 483/710\n",
      "[PREDICTIONS] BATCH: 484/710\n",
      "[PREDICTIONS] BATCH: 485/710\n",
      "[PREDICTIONS] BATCH: 486/710\n",
      "[PREDICTIONS] BATCH: 487/710\n",
      "[PREDICTIONS] BATCH: 488/710\n",
      "[PREDICTIONS] BATCH: 489/710\n",
      "[PREDICTIONS] BATCH: 490/710\n",
      "[PREDICTIONS] BATCH: 491/710\n",
      "[PREDICTIONS] BATCH: 492/710\n",
      "[PREDICTIONS] BATCH: 493/710\n",
      "[PREDICTIONS] BATCH: 494/710\n",
      "[PREDICTIONS] BATCH: 495/710\n",
      "[PREDICTIONS] BATCH: 496/710\n",
      "[PREDICTIONS] BATCH: 497/710\n",
      "[PREDICTIONS] BATCH: 498/710\n",
      "[PREDICTIONS] BATCH: 499/710\n",
      "[PREDICTIONS] BATCH: 500/710\n",
      "[PREDICTIONS] BATCH: 501/710\n",
      "[PREDICTIONS] BATCH: 502/710\n",
      "[PREDICTIONS] BATCH: 503/710\n",
      "[PREDICTIONS] BATCH: 504/710\n",
      "[PREDICTIONS] BATCH: 505/710\n",
      "[PREDICTIONS] BATCH: 506/710\n",
      "[PREDICTIONS] BATCH: 507/710\n",
      "[PREDICTIONS] BATCH: 508/710\n",
      "[PREDICTIONS] BATCH: 509/710\n",
      "[PREDICTIONS] BATCH: 510/710\n",
      "[PREDICTIONS] BATCH: 511/710\n",
      "[PREDICTIONS] BATCH: 512/710\n",
      "[PREDICTIONS] BATCH: 513/710\n",
      "[PREDICTIONS] BATCH: 514/710\n",
      "[PREDICTIONS] BATCH: 515/710\n",
      "[PREDICTIONS] BATCH: 516/710\n",
      "[PREDICTIONS] BATCH: 517/710\n",
      "[PREDICTIONS] BATCH: 518/710\n",
      "[PREDICTIONS] BATCH: 519/710\n",
      "[PREDICTIONS] BATCH: 520/710\n",
      "[PREDICTIONS] BATCH: 521/710\n",
      "[PREDICTIONS] BATCH: 522/710\n",
      "[PREDICTIONS] BATCH: 523/710\n",
      "[PREDICTIONS] BATCH: 524/710\n",
      "[PREDICTIONS] BATCH: 525/710\n",
      "[PREDICTIONS] BATCH: 526/710\n",
      "[PREDICTIONS] BATCH: 527/710\n",
      "[PREDICTIONS] BATCH: 528/710\n",
      "[PREDICTIONS] BATCH: 529/710\n",
      "[PREDICTIONS] BATCH: 530/710\n",
      "[PREDICTIONS] BATCH: 531/710\n",
      "[PREDICTIONS] BATCH: 532/710\n",
      "[PREDICTIONS] BATCH: 533/710\n",
      "[PREDICTIONS] BATCH: 534/710\n",
      "[PREDICTIONS] BATCH: 535/710\n",
      "[PREDICTIONS] BATCH: 536/710\n",
      "[PREDICTIONS] BATCH: 537/710\n",
      "[PREDICTIONS] BATCH: 538/710\n",
      "[PREDICTIONS] BATCH: 539/710\n",
      "[PREDICTIONS] BATCH: 540/710\n",
      "[PREDICTIONS] BATCH: 541/710\n",
      "[PREDICTIONS] BATCH: 542/710\n",
      "[PREDICTIONS] BATCH: 543/710\n",
      "[PREDICTIONS] BATCH: 544/710\n",
      "[PREDICTIONS] BATCH: 545/710\n",
      "[PREDICTIONS] BATCH: 546/710\n",
      "[PREDICTIONS] BATCH: 547/710\n",
      "[PREDICTIONS] BATCH: 548/710\n",
      "[PREDICTIONS] BATCH: 549/710\n",
      "[PREDICTIONS] BATCH: 550/710\n",
      "[PREDICTIONS] BATCH: 551/710\n",
      "[PREDICTIONS] BATCH: 552/710\n",
      "[PREDICTIONS] BATCH: 553/710\n",
      "[PREDICTIONS] BATCH: 554/710\n",
      "[PREDICTIONS] BATCH: 555/710\n",
      "[PREDICTIONS] BATCH: 556/710\n",
      "[PREDICTIONS] BATCH: 557/710\n",
      "[PREDICTIONS] BATCH: 558/710\n",
      "[PREDICTIONS] BATCH: 559/710\n",
      "[PREDICTIONS] BATCH: 560/710\n",
      "[PREDICTIONS] BATCH: 561/710\n",
      "[PREDICTIONS] BATCH: 562/710\n",
      "[PREDICTIONS] BATCH: 563/710\n",
      "[PREDICTIONS] BATCH: 564/710\n",
      "[PREDICTIONS] BATCH: 565/710\n",
      "[PREDICTIONS] BATCH: 566/710\n",
      "[PREDICTIONS] BATCH: 567/710\n",
      "[PREDICTIONS] BATCH: 568/710\n",
      "[PREDICTIONS] BATCH: 569/710\n",
      "[PREDICTIONS] BATCH: 570/710\n",
      "[PREDICTIONS] BATCH: 571/710\n",
      "[PREDICTIONS] BATCH: 572/710\n",
      "[PREDICTIONS] BATCH: 573/710\n",
      "[PREDICTIONS] BATCH: 574/710\n",
      "[PREDICTIONS] BATCH: 575/710\n",
      "[PREDICTIONS] BATCH: 576/710\n",
      "[PREDICTIONS] BATCH: 577/710\n",
      "[PREDICTIONS] BATCH: 578/710\n",
      "[PREDICTIONS] BATCH: 579/710\n",
      "[PREDICTIONS] BATCH: 580/710\n",
      "[PREDICTIONS] BATCH: 581/710\n",
      "[PREDICTIONS] BATCH: 582/710\n",
      "[PREDICTIONS] BATCH: 583/710\n",
      "[PREDICTIONS] BATCH: 584/710\n",
      "[PREDICTIONS] BATCH: 585/710\n",
      "[PREDICTIONS] BATCH: 586/710\n",
      "[PREDICTIONS] BATCH: 587/710\n",
      "[PREDICTIONS] BATCH: 588/710\n",
      "[PREDICTIONS] BATCH: 589/710\n",
      "[PREDICTIONS] BATCH: 590/710\n",
      "[PREDICTIONS] BATCH: 591/710\n",
      "[PREDICTIONS] BATCH: 592/710\n",
      "[PREDICTIONS] BATCH: 593/710\n",
      "[PREDICTIONS] BATCH: 594/710\n",
      "[PREDICTIONS] BATCH: 595/710\n",
      "[PREDICTIONS] BATCH: 596/710\n",
      "[PREDICTIONS] BATCH: 597/710\n",
      "[PREDICTIONS] BATCH: 598/710\n",
      "[PREDICTIONS] BATCH: 599/710\n",
      "[PREDICTIONS] BATCH: 600/710\n",
      "[PREDICTIONS] BATCH: 601/710\n",
      "[PREDICTIONS] BATCH: 602/710\n",
      "[PREDICTIONS] BATCH: 603/710\n",
      "[PREDICTIONS] BATCH: 604/710\n",
      "[PREDICTIONS] BATCH: 605/710\n",
      "[PREDICTIONS] BATCH: 606/710\n",
      "[PREDICTIONS] BATCH: 607/710\n",
      "[PREDICTIONS] BATCH: 608/710\n",
      "[PREDICTIONS] BATCH: 609/710\n",
      "[PREDICTIONS] BATCH: 610/710\n",
      "[PREDICTIONS] BATCH: 611/710\n",
      "[PREDICTIONS] BATCH: 612/710\n",
      "[PREDICTIONS] BATCH: 613/710\n",
      "[PREDICTIONS] BATCH: 614/710\n",
      "[PREDICTIONS] BATCH: 615/710\n",
      "[PREDICTIONS] BATCH: 616/710\n",
      "[PREDICTIONS] BATCH: 617/710\n",
      "[PREDICTIONS] BATCH: 618/710\n",
      "[PREDICTIONS] BATCH: 619/710\n",
      "[PREDICTIONS] BATCH: 620/710\n",
      "[PREDICTIONS] BATCH: 621/710\n",
      "[PREDICTIONS] BATCH: 622/710\n",
      "[PREDICTIONS] BATCH: 623/710\n",
      "[PREDICTIONS] BATCH: 624/710\n",
      "[PREDICTIONS] BATCH: 625/710\n",
      "[PREDICTIONS] BATCH: 626/710\n",
      "[PREDICTIONS] BATCH: 627/710\n",
      "[PREDICTIONS] BATCH: 628/710\n",
      "[PREDICTIONS] BATCH: 629/710\n",
      "[PREDICTIONS] BATCH: 630/710\n",
      "[PREDICTIONS] BATCH: 631/710\n",
      "[PREDICTIONS] BATCH: 632/710\n",
      "[PREDICTIONS] BATCH: 633/710\n",
      "[PREDICTIONS] BATCH: 634/710\n",
      "[PREDICTIONS] BATCH: 635/710\n",
      "[PREDICTIONS] BATCH: 636/710\n",
      "[PREDICTIONS] BATCH: 637/710\n",
      "[PREDICTIONS] BATCH: 638/710\n",
      "[PREDICTIONS] BATCH: 639/710\n",
      "[PREDICTIONS] BATCH: 640/710\n",
      "[PREDICTIONS] BATCH: 641/710\n",
      "[PREDICTIONS] BATCH: 642/710\n",
      "[PREDICTIONS] BATCH: 643/710\n",
      "[PREDICTIONS] BATCH: 644/710\n",
      "[PREDICTIONS] BATCH: 645/710\n",
      "[PREDICTIONS] BATCH: 646/710\n",
      "[PREDICTIONS] BATCH: 647/710\n",
      "[PREDICTIONS] BATCH: 648/710\n",
      "[PREDICTIONS] BATCH: 649/710\n",
      "[PREDICTIONS] BATCH: 650/710\n",
      "[PREDICTIONS] BATCH: 651/710\n",
      "[PREDICTIONS] BATCH: 652/710\n",
      "[PREDICTIONS] BATCH: 653/710\n",
      "[PREDICTIONS] BATCH: 654/710\n",
      "[PREDICTIONS] BATCH: 655/710\n",
      "[PREDICTIONS] BATCH: 656/710\n",
      "[PREDICTIONS] BATCH: 657/710\n",
      "[PREDICTIONS] BATCH: 658/710\n",
      "[PREDICTIONS] BATCH: 659/710\n",
      "[PREDICTIONS] BATCH: 660/710\n",
      "[PREDICTIONS] BATCH: 661/710\n",
      "[PREDICTIONS] BATCH: 662/710\n",
      "[PREDICTIONS] BATCH: 663/710\n",
      "[PREDICTIONS] BATCH: 664/710\n",
      "[PREDICTIONS] BATCH: 665/710\n",
      "[PREDICTIONS] BATCH: 666/710\n",
      "[PREDICTIONS] BATCH: 667/710\n",
      "[PREDICTIONS] BATCH: 668/710\n",
      "[PREDICTIONS] BATCH: 669/710\n",
      "[PREDICTIONS] BATCH: 670/710\n",
      "[PREDICTIONS] BATCH: 671/710\n",
      "[PREDICTIONS] BATCH: 672/710\n",
      "[PREDICTIONS] BATCH: 673/710\n",
      "[PREDICTIONS] BATCH: 674/710\n",
      "[PREDICTIONS] BATCH: 675/710\n",
      "[PREDICTIONS] BATCH: 676/710\n",
      "[PREDICTIONS] BATCH: 677/710\n",
      "[PREDICTIONS] BATCH: 678/710\n",
      "[PREDICTIONS] BATCH: 679/710\n",
      "[PREDICTIONS] BATCH: 680/710\n",
      "[PREDICTIONS] BATCH: 681/710\n",
      "[PREDICTIONS] BATCH: 682/710\n",
      "[PREDICTIONS] BATCH: 683/710\n",
      "[PREDICTIONS] BATCH: 684/710\n",
      "[PREDICTIONS] BATCH: 685/710\n",
      "[PREDICTIONS] BATCH: 686/710\n",
      "[PREDICTIONS] BATCH: 687/710\n",
      "[PREDICTIONS] BATCH: 688/710\n",
      "[PREDICTIONS] BATCH: 689/710\n",
      "[PREDICTIONS] BATCH: 690/710\n",
      "[PREDICTIONS] BATCH: 691/710\n",
      "[PREDICTIONS] BATCH: 692/710\n",
      "[PREDICTIONS] BATCH: 693/710\n",
      "[PREDICTIONS] BATCH: 694/710\n",
      "[PREDICTIONS] BATCH: 695/710\n",
      "[PREDICTIONS] BATCH: 696/710\n",
      "[PREDICTIONS] BATCH: 697/710\n",
      "[PREDICTIONS] BATCH: 698/710\n",
      "[PREDICTIONS] BATCH: 699/710\n",
      "[PREDICTIONS] BATCH: 700/710\n",
      "[PREDICTIONS] BATCH: 701/710\n",
      "[PREDICTIONS] BATCH: 702/710\n",
      "[PREDICTIONS] BATCH: 703/710\n",
      "[PREDICTIONS] BATCH: 704/710\n",
      "[PREDICTIONS] BATCH: 705/710\n",
      "[PREDICTIONS] BATCH: 706/710\n",
      "[PREDICTIONS] BATCH: 707/710\n",
      "[PREDICTIONS] BATCH: 708/710\n",
      "[PREDICTIONS] BATCH: 709/710\n",
      "[PREDICTIONS] BATCH: 710/710\n",
      "SPAM: 0.9972\n",
      "TOXIC: 0.8415\n",
      "OK: 0.9277\n",
      "TOTAL: 0.9234\n"
     ]
    }
   ],
   "source": [
    "accuracy_results = calculate_class_accuracy(model, dl_valid)\n",
    "for class_name, acc in accuracy_results.items():\n",
    "    print(f\"{class_name}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1765cb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37d7aed2b264dca80b71cf01ce825f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a80a97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(\"./analysis/neural_training/rugpt3_spam_toxic_classifier/\")\n",
    "model.save_pretrained(\"./analysis/neural_training/rugpt3_spam_toxic_classifier/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8016efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"arseso/gpt2_spam_toxic_classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25a2a960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00b7670f4704ef5be1d6c180e1c5810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b653ab8e30a245a2a44ac6bdd9578d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/arseso/gpt2_spam_toxic_classifier/commit/c90a571c2a7495796bf8ca46876e5a408e812e13', commit_message='Upload tokenizer for ruGPT-3 small', commit_description='', oid='c90a571c2a7495796bf8ca46876e5a408e812e13', pr_url=None, repo_url=RepoUrl('https://huggingface.co/arseso/gpt2_spam_toxic_classifier', endpoint='https://huggingface.co', repo_type='model', repo_id='arseso/gpt2_spam_toxic_classifier'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\n",
    "    repo_id,\n",
    "    commit_message=\"0.20235\"\n",
    ")\n",
    "\n",
    "# Загружаем токенизатор\n",
    "tokenizer.push_to_hub(\n",
    "    repo_id,\n",
    "    commit_message=\"Upload tokenizer for ruGPT-3 small\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
