from enum import Enum
import torch
from transformers import AutoConfig, AutoTokenizer, AutoModelForSequenceClassification
from typing import Dict, Any
import numpy as np

from models import VERDICT

class Verdict(str, Enum):
    SPAM = "SPAM"
    TOXIC = "TOXIC" 
    OK = "OK"

class NeuralNet:
    def __init__(self, model_repo: str):
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(model_repo)
            
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            
            self.model = AutoModelForSequenceClassification.from_pretrained(
                model_repo,
                num_labels=3,
                ignore_mismatched_sizes=True
            )
            self.model.eval()
            self._model_loaded = True
            print(f"âœ… ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°: {model_repo}")
            
        except Exception as e:
            print(f"âš ï¸  ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: {e}")
            print("ğŸ”„ Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ·Ğ°Ğ³Ğ»ÑƒÑˆĞºĞ°")
            self._model_loaded = False
    
    def predict(self, text: str) -> Verdict:
        if not self._model_loaded:
            return Verdict.OK
        
        try:
            text = text.lower().replace(" ", "")
            
            inputs = self.tokenizer(
                text, 
                return_tensors="pt",
                truncation=True,
                padding=True,
                max_length=512
            )
            
            if 'token_type_ids' in inputs:
                inputs.pop('token_type_ids')
            
            with torch.no_grad():
                outputs = self.model(**inputs)
                
                if hasattr(outputs, 'logits'):
                    logits = outputs.logits
                else:
                    return Verdict.OK
                
                probabilities = torch.nn.functional.softmax(logits, dim=-1)
                probs = probabilities.cpu().numpy()[0]
                
                if len(probs) != 3:
                    return Verdict.OK
                
                predicted_label = int(np.argmax(probs))
                
                return [Verdict.SPAM, Verdict.TOXIC, Verdict.OK][predicted_label]
                
        except Exception as e:
            print(f"âš ï¸  ĞÑˆĞ¸Ğ±ĞºĞ° Ğ² predict: {e}")
            return Verdict.OK


if __name__ == "__main__":
    from env import Settings
    nn = NeuralNet(model_repo=Settings.MODEL_REPO)
    tests = [
        "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚ ĞºĞ°Ğº Ğ´ĞµĞ»Ğ°", # SPAM Ğ¸ Ğ½ĞµÑ…ÑƒĞ¹ ÑĞ¿Ğ¾Ñ€Ğ¸Ñ‚ÑŒ Ğ¼Ğ¸ÑÑŒĞµ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸Ğº
        "Ğ²Ğ¸Ğ°Ğ³Ñ€Ğ° 1500 Ñ€ÑƒĞ±Ğ»ĞµĞ¹ ÑĞºĞ¸Ğ´ĞºĞ°",
        "Ğ¢Ñ‹ Ğ¸Ğ´Ğ¸Ğ¾Ñ‚",
        "Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ°Ñ Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ğ° ÑĞµĞ³Ğ¾Ğ´Ğ½Ñ"
    ]

    for text in tests:
        result = nn.predict(text)
        print(f"'{text}' -> {result}")